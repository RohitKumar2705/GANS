{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl94I/Kn7ePDxEMPpp195M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohitKumar2705/GANS/blob/main/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hnaR1giXst5T"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Flatten ,Dropout,Reshape,Activation ,BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D,Conv2DTranspose\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "\n",
        "# input image dimensions\n",
        "img_shape = (img_rows,img_cols,channels)\n",
        "\n",
        "z_dim = 100"
      ],
      "metadata": {
        "id": "ltVR9y3XyTG8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(z_dim):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(256*7**7,input_dim = z_dim))\n",
        "  model.add(Reshape(7,7,256))\n",
        "\n",
        "  # transpose convolutional\n",
        "  model.add(Conv2DTranspose(128,kernel_size = 3,strides = 2, padding = 'same'))\n",
        "\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(LeakyReLU(alpha = 0.01))\n",
        "\n",
        "  model.add(Conv2DTranspose(64,kernel_size = 4,strides = 1,padding = 'same'))\n",
        "\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Transposed convolution layer, from 14x14x64 to 28x28x1 tensor\n",
        "  model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "  model.add(Activation('tanh'))\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "g8bGsL0cyzC5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32,kernel_size = 3,\n",
        "                   strides = 2,\n",
        "                   input_shape = img_shape,\n",
        "                   padding = 'same'))\n",
        "  # leaky relu activation\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  # leaky leaky relu activation\n",
        "  model.add(LeakyReLU(alpha = 0.01))\n",
        "\n",
        "  # Convolutional layer, from 7x7x64 tensor into 3x3x128 tensor\n",
        "  model.add(\n",
        "        Conv2D(128,\n",
        "               kernel_size=3,\n",
        "               strides=2,\n",
        "               input_shape=img_shape,\n",
        "               padding='same'))\n",
        "\n",
        "    # Batch normalization\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "  model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Output layer with sigmoid activation\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "YuGKmVmG0EOh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gan(generator,discriminator):\n",
        "  model = Sequential()\n",
        "  model.add(generator)\n",
        "  model.add(discriminator)\n",
        "  return model"
      ],
      "metadata": {
        "id": "hUXU5VGN1sqA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build and compile the discriminator\n",
        "discriminator = build_discriminator(img_shape)\n",
        "discriminator.compile(loss = 'binary_crossentropy',optimizer = Adam(),metrics = ['accuracy'])\n",
        "\n",
        "# build the generator\n",
        "generator = build_generator(z_dim)\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "# build gan\n",
        "gan = build_gan(generator,discriminator)\n",
        "gan.compile(loss = 'binary_crossentropy',optimizer = Adam())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DKik61o16pI",
        "outputId": "42f3710b-3198-4f5c-9951-4ced40917ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "accurices = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "def train(iterations,batch_size,sample_interval):\n",
        "  (X_train,_),(_,_) =  mnist.load_data()\n",
        "\n",
        "  X_train = X_train/127.5 - 1.0\n",
        "  X_train = np.expand_dims(X_train,axis = 3)\n",
        "  real = np.ones((batch_size , 1))\n",
        "  fake = np.zeros((batch_size,1))\n",
        "\n",
        "  for iteration in range(iterations):\n",
        "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "    imgs = X_train[idx]\n",
        "\n",
        "    # generate a batch of fake image\n",
        "    z = np.random.normal(0,1,(batch_size,100))\n",
        "    gen_imgs = generator.predict(z)\n",
        "\n",
        "    # train discriminator\n",
        "    d_loss_real = discriminator.train_on_loss(imgs,real)\n",
        "    d_loss_fake = discriminator.train_on_loss(gen_imgs,fake)\n",
        "    d_loss,accuracy = 0.5*np.add(d_loss_real,d_loss_fake)\n",
        "    # Generate a batch of fake images\n",
        "    z = np.random.normal(0, 1, (batch_size, 100))\n",
        "    gen_imgs = generator.predict(z)\n",
        "\n",
        "        # Train Generator\n",
        "    g_loss = gan.train_on_batch(z, real)\n",
        "\n",
        "    if (iteration + 1) % sample_interval == 0:\n",
        "\n",
        "            # Save losses and accuracies so they can be plotted after training\n",
        "            losses.append((d_loss, g_loss))\n",
        "            accuracies.append(100.0 * accuracy)\n",
        "            iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "            # Output training progress\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "                  (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n",
        "\n",
        "            # Output a sample of generated image\n",
        "            sample_images(generator)"
      ],
      "metadata": {
        "id": "t7GL1_pA2_Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict(z)\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(4, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1"
      ],
      "metadata": {
        "id": "79GR7gbN5Pwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "iterations = 5000\n",
        "batch_size = 128\n",
        "sample_interval = 1000\n",
        "\n",
        "# Train the DCGAN for the specified number of iterations\n",
        "train(iterations, batch_size, sample_interval)"
      ],
      "metadata": {
        "id": "0sEq9liI5UbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "losses = np.array(losses)\n",
        "\n",
        "# Plot training losses for Discriminator and Generator\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(iteration_checkpoints, losses.T[0], label=\"Discriminator loss\")\n",
        "plt.plot(iteration_checkpoints, losses.T[1], label=\"Generator loss\")\n",
        "\n",
        "plt.xticks(iteration_checkpoints, rotation=90)\n",
        "\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "5JDjRYRk5evi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = np.array(accuracies)\n",
        "\n",
        "# Plot Discriminator accuracy\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(iteration_checkpoints, accuracies, label=\"Discriminator accuracy\")\n",
        "\n",
        "plt.xticks(iteration_checkpoints, rotation=90)\n",
        "plt.yticks(range(0, 100, 5))\n",
        "\n",
        "plt.title(\"Discriminator Accuracy\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "fVWacVYb5hmT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}